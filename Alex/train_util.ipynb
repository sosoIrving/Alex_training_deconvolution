{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "################ batch creation functions #####################\n",
    "\n",
    "def onehot(index):\n",
    "\t\"\"\" It creates a one-hot vector with a 1.0 in\n",
    "\t\tposition represented by index\n",
    "\t\"\"\"\n",
    "\tonehot = np.zeros(1000)\n",
    "\tonehot[index] = 1.0\n",
    "\treturn onehot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_batch(batch_size, images_source, wnid_labels):\n",
    "    \"\"\"\n",
    "\tIt returns a batch of single images (no data-augmentation)\n",
    "\t\tILSVRC 2012 training set folder should be srtuctured like this:\n",
    "\t\tILSVRC2012_img_train\n",
    "\t\t\t|_n01440764\n",
    "\t\t\t|_n01443537\n",
    "\t\t\t|_n01484850\n",
    "\t\t\t|_n01491361\n",
    "\t\t\t|_ ...\n",
    "\t\tArgs:\n",
    "\t\t\tbatch_size: need explanation? :)\n",
    "\t\t\timages_sources: path to ILSVRC 2012 training set folder\n",
    "\t\t\twnid_labels: list of ImageNet wnid lexicographically ordered\n",
    "\t\tReturns:\n",
    "\t\t\tbatch_images: a tensor (numpy array of images) of shape [batch_size, width, height, channels]\n",
    "\t\t\tbatch_labels: a tensor (numpy array of onehot vectors) of shape [batch_size, 1000]\n",
    "    \"\"\"\n",
    "\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # random class choice\n",
    "        # (randomly choose a folder of image of the same class from a list of previously sorted wnids)\n",
    "        class_index = random.randint(0,999)\n",
    "\n",
    "        folder = wnid_labels[class_index]               #??? why wnid_labels\n",
    "        batch_images.append(read_image(os.path.join(images_source,folder)))\n",
    "        batch_labels.append(onehot(class_index))\n",
    "\n",
    "    np.vstack(batch_images)                     #????????1 np.vstack\n",
    "    np.vstack(batch_labels)\n",
    "\n",
    "    return batch_images,batch_labels\n",
    "\n",
    "def read_image(images_folder):\n",
    "    \"\"\"\n",
    "    It reads a single image file into a numpy array and preprocss it       # focus the preprocss\n",
    "        :param\n",
    "                    image_folder: path where to random choose an image\n",
    "        :return:\n",
    "                    im_array: the numpy array of the image [width,height,channels]\n",
    "    \"\"\"\n",
    "\n",
    "    # random image chice inside the folder\n",
    "    # ï¼ˆrandomly choose an image inside the folder)\n",
    "    image_path = os.path.join(images_folder,random.choice(os.listdir(images_folder)))           #??????\n",
    "\n",
    "    # load and normalize image\n",
    "    im_array = preprocess_image(image_path)\n",
    "\n",
    "    return im_array\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "\t\"\"\" It reads an image, it resize it to have the lowest dimesnion of 256px,\n",
    "\t\tit randomly choose a 224x224 crop inside the resized image and normilize the numpy\n",
    "\t\tarray subtracting the ImageNet training set mean\n",
    "\t\tArgs:\n",
    "\t\t\timages_path: path of the image\n",
    "\t\tReturns:\n",
    "\t\t\tcropped_im_array: the numpy array of the image normalized [width, height, channels]\n",
    "\t\"\"\"\n",
    "\tIMAGENET_MEAN = [123.68, 116.779, 103.939] # rgb format\n",
    "\n",
    "\timg = Image.open(image_path).convert('RGB')\n",
    "\n",
    "\t# resize of the image (setting lowest dimension to 256px)\n",
    "\tif img.size[0] < img.size[1]:\n",
    "\t\th = int(float(256 * img.size[1]) / img.size[0])\n",
    "\t\timg = img.resize((256, h), Image.ANTIALIAS)\n",
    "\telse:\n",
    "\t\tw = int(float(256 * img.size[0]) / img.size[1])\n",
    "\t\timg = img.resize((w, 256), Image.ANTIALIAS)\n",
    "\n",
    "    # random 244x224 patch\n",
    "\tx = random.randint(0, img.size[0] - 224)\n",
    "\ty = random.randint(0, img.size[1] - 224)\n",
    "\timg_cropped = img.crop((x, y, x + 224, y + 224))\n",
    "\n",
    "\tcropped_im_array = np.array(img_cropped, dtype=np.float32)\n",
    "\n",
    "\tfor i in range(3):\n",
    "\t\tcropped_im_array[:,:,i] -= IMAGENET_MEAN[i]\n",
    "\n",
    "\t#for i in range(3):\n",
    "\t#\tmean = np.mean(img_c1_np[:,:,i])\n",
    "\t#\tstddev = np.std(img_c1_np[:,:,i])\n",
    "\t#\timg_c1_np[:,:,i] -= mean\n",
    "\t#\timg_c1_np[:,:,i] /= stddev\n",
    "\n",
    "\treturn cropped_im_array\n",
    "\n",
    "\n",
    "def read_validation_batch(batch_size, validation_source, annotations):\n",
    "\tbatch_images_val = []\n",
    "\tbatch_labels_val = []\n",
    "\n",
    "\timages_val = sorted(os.listdir(validation_source))\n",
    "\n",
    "\t# reading groundthruths labels\n",
    "\twith open(annotations) as f:\n",
    "\t\tgt_idxs = f.readlines()\n",
    "\t\tgt_idxs = [(int(x.strip()) - 1) for x in gt_idxs]\n",
    "\n",
    "\tfor i in range(batch_size):\n",
    "\t\t# random image choice\n",
    "\t\tidx = random.randint(0, len(images_val) - 1)\n",
    "\n",
    "\t\timage = images_val[idx]\n",
    "\t\tbatch_images_val.append(preprocess_image(os.path.join(validation_source, image)))\n",
    "\t\tbatch_labels_val.append(onehot(gt_idxs[idx]))\n",
    "\n",
    "\tnp.vstack(batch_images_val)\n",
    "\tnp.vstack(batch_labels_val)\n",
    "\treturn batch_images_val, batch_labels_val\n",
    "\n",
    "\n",
    "################ Other helper procedures #####################\n",
    "\n",
    "def load_imagenet_meta(meta_path):\n",
    "    \"\"\" It reads ImageNet metadata from ILSVRC 2012 dev tool file\n",
    "        Args:\n",
    "            meta_path: path to ImageNet metadata file\n",
    "        Returns:\n",
    "            wnids: list of ImageNet wnids labels (as strings)\n",
    "            words: list of words (as strings) referring to wnids labels and describing the classes\n",
    "    \"\"\"\n",
    "    metadata = loadmat(meta_path, struct_as_record=False)\n",
    "\n",
    "    # ['ILSVRC2012_ID', 'WNID', 'words', 'gloss', 'num_children', 'children', 'wordnet_height', 'num_train_images']\n",
    "    synsets = np.squeeze(metadata['synsets'])\n",
    "    ids = np.squeeze(np.array([s.ILSVRC2012_ID for s in synsets]))\n",
    "    wnids = np.squeeze(np.array([s.WNID for s in synsets]))\n",
    "    words = np.squeeze(np.array([s.words for s in synsets]))\n",
    "    return wnids, words\n",
    "\n",
    "\n",
    "def read_test_labels(annotations_path):\n",
    "    \"\"\" It reads groundthruth labels from ILSRVC 2012 annotations file\n",
    "        Args:\n",
    "            annotations_path: path to the annotations file\n",
    "        Returns:\n",
    "            gt_labels: a numpy vector of onehot labels\n",
    "    \"\"\"\n",
    "    gt_labels = []\n",
    "\n",
    "    # reading groundthruths labels from ilsvrc12 annotations file\n",
    "    with open(annotations_path) as f:\n",
    "        gt_idxs = f.readlines()\n",
    "        gt_idxs = [(int(x.strip()) - 1) for x in gt_idxs]\n",
    "\n",
    "    for gt in gt_idxs:\n",
    "        gt_labels.append(onehot(gt))\n",
    "\n",
    "    np.vstack(gt_labels)\n",
    "\n",
    "    return gt_labels\n",
    "\n",
    "\n",
    "def format_time(time):\n",
    "    \"\"\" It formats a datetime to print it\n",
    "        Args:\n",
    "            time: datetime\n",
    "        Returns:\n",
    "            a formatted string representing time\n",
    "    \"\"\"\n",
    "    m, s = divmod(time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    return ('{:02d}d {:02d}h {:02d}m {:02d}s').format(int(d), int(h), int(m), int(s))\n",
    "\n",
    "\n",
    "def imagenet_size(im_source):\n",
    "    \"\"\" It calculates the number of examples in ImageNet training-set\n",
    "        Args:\n",
    "            im_source: path to ILSVRC 2012 training set folder\n",
    "        Returns:\n",
    "            n: the number of training examples\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    for d in os.listdir(im_source):\n",
    "        for f in os.listdir(os.path.join(im_source, d)):\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
