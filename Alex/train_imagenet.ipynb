{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 09:42:57.134424 140020895729408 deprecation.py:323] From <ipython-input-1-f8954d892f91>:47: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0823 09:42:57.179473 140020895729408 deprecation.py:323] From <ipython-input-1-f8954d892f91>:75: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "W0823 09:42:57.179893 140020895729408 deprecation.py:323] From <ipython-input-1-f8954d892f91>:75: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "W0823 09:42:57.182478 140020895729408 deprecation.py:323] From /home/Irving/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "W0823 09:42:57.182885 140020895729408 deprecation.py:323] From /home/Irving/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "W0823 09:42:57.183263 140020895729408 deprecation.py:323] From /home/Irving/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "W0823 09:42:57.310949 140020895729408 deprecation_wrapper.py:119] From /home/Irving/AI/Alex/alexnet_model.py:6: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0823 09:42:57.354243 140020895729408 deprecation.py:506] From /home/Irving/AI/Alex/alexnet_model.py:69: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0823 09:42:57.365479 140020895729408 deprecation_wrapper.py:119] From /home/Irving/AI/Alex/alexnet_model.py:76: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0823 09:42:57.391002 140020895729408 deprecation.py:323] From /home/Irving/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100, Learning_rate: 0.000050, Time: 9s Loss: 13.847442\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8954d892f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mloss_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import alexnet_model\n",
    " \n",
    "imageWidth = 227\n",
    "imageHeight = 227\n",
    "imageDepth = 3\n",
    "batch_size = 128\n",
    "resize_min = 256\n",
    " \n",
    "# Parse TFRECORD and distort the image for train\n",
    "def _parse_function(example_proto):\n",
    "    features = {\"image\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"height\": tf.FixedLenFeature([1], tf.int64, default_value=[0]),\n",
    "                \"width\": tf.FixedLenFeature([1], tf.int64, default_value=[0]),\n",
    "                \"channels\": tf.FixedLenFeature([1], tf.int64, default_value=[3]),\n",
    "                \"colorspace\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"img_format\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"label\": tf.FixedLenFeature([1], tf.int64, default_value=[0]),\n",
    "                \"bbox_xmin\": tf.VarLenFeature(tf.float32),\n",
    "                \"bbox_xmax\": tf.VarLenFeature(tf.float32),\n",
    "                \"bbox_ymin\": tf.VarLenFeature(tf.float32),\n",
    "                \"bbox_ymax\": tf.VarLenFeature(tf.float32),\n",
    "                \"text\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"filename\": tf.FixedLenFeature([], tf.string, default_value=\"\")\n",
    "               }\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    \n",
    "    xmin = tf.expand_dims(parsed_features[\"bbox_xmin\"].values, 0)\n",
    "    xmax = tf.expand_dims(parsed_features[\"bbox_xmax\"].values, 0)\n",
    "    ymin = tf.expand_dims(parsed_features[\"bbox_ymin\"].values, 0)\n",
    "    ymax = tf.expand_dims(parsed_features[\"bbox_ymax\"].values, 0)\n",
    "    \n",
    "    bbox = tf.concat(axis=0, values=[ymin, xmin, ymax, xmax])\n",
    "    bbox = tf.expand_dims(bbox, 0)\n",
    "    bbox = tf.transpose(bbox, [0, 2, 1])\n",
    "    \n",
    "    height = parsed_features[\"height\"]\n",
    "    width = parsed_features[\"width\"]\n",
    "    channels = parsed_features[\"channels\"]\n",
    " \n",
    "    bbox_begin, bbox_size, bbox_for_draw = tf.image.sample_distorted_bounding_box(\n",
    "        tf.concat(axis=0, values=[height, width, channels]),\n",
    "        bounding_boxes=bbox,\n",
    "        min_object_covered=0.1,\n",
    "        use_image_if_no_bounding_boxes=True)\n",
    " \n",
    "    # Reassemble the bounding box in the format the crop op requires.\n",
    "    offset_y, offset_x, _ = tf.unstack(bbox_begin)\n",
    "    target_height, target_width, _ = tf.unstack(bbox_size)\n",
    "    crop_window = tf.cast(tf.stack([offset_y, offset_x, target_height, target_width]), tf.int32)\n",
    "    \n",
    "    # Use the fused decode and crop op here, which is faster than each in series.\n",
    "    cropped = tf.image.decode_and_crop_jpeg(parsed_features[\"image\"], crop_window, channels=3)\n",
    " \n",
    "    # Flip to add a little more random distortion in.\n",
    "    cropped = tf.image.random_flip_left_right(cropped)\n",
    "    \n",
    "    image_train = tf.image.resize_images(cropped, [imageHeight, imageWidth], \n",
    "                                         method=tf.image.ResizeMethod.BILINEAR,align_corners=False)\n",
    "    \n",
    "    image_train = tf.cast(image_train, tf.uint8)\n",
    "    image_train = tf.image.convert_image_dtype(image_train, tf.float32)\n",
    "    return image_train, parsed_features[\"label\"][0], parsed_features[\"text\"], parsed_features[\"filename\"]\n",
    " \n",
    "with tf.device('/cpu:0'):\n",
    "    train_files_names = os.listdir('/home/Irving/AI/Alex/Data/train_tf/')\n",
    "    train_files = ['/home/Irving/AI/Alex/Data/train_tf/'+item for item in train_files_names]\n",
    "    dataset_train = tf.data.TFRecordDataset(train_files)\n",
    "    dataset_train = dataset_train.map(_parse_function, num_parallel_calls=6)\n",
    "    dataset_train = dataset_train.repeat(10)\n",
    "    dataset_train = dataset_train.batch(batch_size)\n",
    "    dataset_train = dataset_train.prefetch(batch_size)\n",
    "    iterator = tf.data.Iterator.from_structure(dataset_train.output_types, dataset_train.output_shapes)\n",
    "    next_images, next_labels, next_text, next_filenames = iterator.get_next()\n",
    "    train_init_op = iterator.make_initializer(dataset_train)\n",
    " \n",
    "def _parse_test_function(example_proto):\n",
    "    features = {\"image\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"height\": tf.FixedLenFeature([1], tf.int64, default_value=[0]),\n",
    "                \"width\": tf.FixedLenFeature([1], tf.int64, default_value=[0]),\n",
    "                \"channels\": tf.FixedLenFeature([1], tf.int64, default_value=[3]),\n",
    "                \"colorspace\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"img_format\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"label\": tf.FixedLenFeature([1], tf.int64, default_value=[0]),\n",
    "                \"bbox_xmin\": tf.VarLenFeature(tf.float32),\n",
    "                \"bbox_xmax\": tf.VarLenFeature(tf.float32),\n",
    "                \"bbox_ymin\": tf.VarLenFeature(tf.float32),\n",
    "                \"bbox_ymax\": tf.VarLenFeature(tf.float32),\n",
    "                \"text\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"filename\": tf.FixedLenFeature([], tf.string, default_value=\"\")\n",
    "               }\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    image_decoded = tf.image.decode_jpeg(parsed_features[\"image\"], channels=3)\n",
    "    shape = tf.shape(image_decoded)\n",
    "    height, width = shape[0], shape[1]\n",
    "    resized_height, resized_width = tf.cond(height<width,\n",
    "        lambda: (resize_min, tf.cast(tf.multiply(tf.cast(width, tf.float64),tf.divide(resize_min,height)), tf.int32)),\n",
    "        lambda: (tf.cast(tf.multiply(tf.cast(height, tf.float64),tf.divide(resize_min,width)), tf.int32), resize_min))\n",
    "    image_resized = tf.image.resize_images(image_decoded, [resized_height, resized_width])\n",
    "    image_resized = tf.cast(image_resized, tf.uint8)\n",
    "    image_resized = tf.image.convert_image_dtype(image_resized, tf.float32)\n",
    "    \n",
    "    # calculate how many to be center crop\n",
    "    shape = tf.shape(image_resized)  \n",
    "    height, width = shape[0], shape[1]\n",
    "    amount_to_be_cropped_h = (height - imageHeight)\n",
    "    crop_top = amount_to_be_cropped_h // 2\n",
    "    amount_to_be_cropped_w = (width - imageWidth)\n",
    "    crop_left = amount_to_be_cropped_w // 2\n",
    "    image_valid = tf.slice(image_resized, [crop_top, crop_left, 0], [imageHeight, imageWidth, -1])\n",
    "    return image_valid, parsed_features[\"label\"][0], parsed_features[\"text\"], parsed_features[\"filename\"]\n",
    " \n",
    "with tf.device('/cpu:0'):\n",
    "    valid_files_names = os.listdir('/home/Irving/AI/Alex/Data/valid_tf/')\n",
    "    valid_files = ['/home/Irving/AI/Alex/Data/valid_tf/'+item for item in valid_files_names]\n",
    "    dataset_valid = tf.data.TFRecordDataset(valid_files)\n",
    "    dataset_valid = dataset_valid.map(_parse_test_function, num_parallel_calls=6)\n",
    "    dataset_valid = dataset_valid.batch(batch_size)\n",
    "    dataset_valid = dataset_valid.prefetch(batch_size)\n",
    "    iterator_valid = tf.data.Iterator.from_structure(dataset_valid.output_types, dataset_valid.output_shapes)\n",
    "    next_valid_images, next_valid_labels, next_valid_text, next_valid_filenames = iterator_valid.get_next()\n",
    "    valid_init_op = iterator_valid.make_initializer(dataset_valid)\n",
    " \n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "epoch_steps = int(1281167/batch_size)\n",
    "boundaries = [50000,80000,100000]\n",
    "values = [0.00005,0.00001,0.000005,0.000001]\n",
    "learning_rate = tf.train.piecewise_constant(global_step, boundaries, values)\n",
    "lr_summary = tf.summary.scalar('learning_rate', learning_rate)\n",
    " \n",
    "result = alexnet_model.inference(next_images, dropout_rate=0.5, wd=0.00005)\n",
    "output_result_scores = tf.nn.softmax(result)\n",
    "output_result = tf.argmax(output_result_scores, 1)\n",
    " \n",
    "#Calculate the cross entropy loss\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=next_labels, logits=result)\n",
    "cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "tf.add_to_collection('losses', cross_entropy_mean)\n",
    " \n",
    "#Add the l2 weights to the loss\n",
    "loss = tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    " \n",
    "#Define the optimizer\n",
    "#opt_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "opt_op = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step) \n",
    "\n",
    " \n",
    "#Get the inference logits by the model for the validation images\n",
    "result_valid = alexnet_model.inference(next_valid_images, dropout_rate=0.5, wd=None)\n",
    "output_valid_scores = tf.nn.softmax(result_valid)\n",
    "output_valid_result = tf.argmax(output_valid_scores, 1)\n",
    "accuracy_valid_batch = tf.reduce_mean(tf.cast(tf.equal(next_valid_labels, tf.argmax(output_valid_scores, 1)), tf.float32))\n",
    "accuracy_valid_top_5 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(output_valid_scores, next_valid_labels, k=5), tf.float32))\n",
    "acc_1_summary = tf.summary.scalar('accuracy_valid_top_1', accuracy_valid_batch)\n",
    "acc_2_summary = tf.summary.scalar('accuracy_valid_top_5', accuracy_valid_top_5)\n",
    " \n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    #saver.restore(sess, \"model/model.ckpt-5000\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run([global_step, train_init_op, valid_init_op])\n",
    "    total_loss = 0.0\n",
    "    epoch = 0\n",
    "    starttime = time.time()\n",
    "    while(True):\n",
    "        try:\n",
    "            loss_t, lr, step, _ = sess.run([loss, learning_rate, global_step, opt_op])\n",
    "            total_loss += loss_t\n",
    "            \n",
    "            if step%100==0:\n",
    "                print(\"step: %i, Learning_rate: %f, Time: %is Loss: %f\"%(step, lr, int(time.time()-starttime), total_loss/100))\n",
    "                total_loss = 0.0\n",
    "                starttime = time.time()\n",
    "            \n",
    "            if step%5000==0:\n",
    "                save_path = saver.save(sess, \"/home/Irving/AI/Alex/Data/model/model.ckpt\", global_step=global_step)\n",
    "                truepredict = 0.0\n",
    "                truepredict_top5 = 0.0\n",
    "                valid_count = 0\n",
    "                while(True):\n",
    "                    try:\n",
    "                        acc_valid_1, acc_valid_5, valid_result_t = sess.run([accuracy_valid_batch, accuracy_valid_top_5, output_valid_result])\n",
    "                        truepredict += acc_valid_1\n",
    "                        truepredict_top5 += acc_valid_5\n",
    "                        valid_count += 1\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        print(\"valid accuracy of top 1: %f\" % (truepredict/valid_count))\n",
    "                        print(\"valid accuracy of top 5: %f\" % (truepredict_top5/valid_count))\n",
    "                        break\n",
    "                starttime = time.time()\n",
    "                sess.run([valid_init_op])\n",
    "          \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
