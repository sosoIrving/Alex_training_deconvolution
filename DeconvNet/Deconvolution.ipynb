{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from alexnet import AlexNet, alexnet_model, preprocess_image_batch\n",
    "from activations import get_strongest_filter, get_strongest_filters\n",
    "from validation import get_path_from_id\n",
    "from deconvolution_additional_layers import DeconvLayers\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from random import randint\n",
    "from shutil import copyfile, rmtree\n",
    "\n",
    "\n",
    "class Deconvolution:\n",
    "    channels = AlexNet.channels\n",
    "\n",
    "    def __init__(self, conv_base_model=None):\n",
    "        # Set convolutional model and submodels, which get activations after given layer\n",
    "        self.conv_base_model = conv_base_model if conv_base_model else alexnet_model()\n",
    "        self.conv_sub_models = [None] + [AlexNet(i, self.conv_base_model) for i in (1, 2, 3, 4, 5)]  # Make it 1-based\n",
    "                                                                # Get deconvolutional layers from Deconv_Layers instance\n",
    "\n",
    "        # Get deconvolutional layers from Deconv_Layers instance\n",
    "        DeconvLayers_Instance = DeconvLayers(self.conv_base_model)\n",
    "        self.deconv_layers = DeconvLayers_Instance.deconv_layers\n",
    "        self.bias3D = DeconvLayers_Instance.bias3D\n",
    "\n",
    "        # This attributes will be filled by 'project_down' method\n",
    "        self.array = None  # Tensor being projected down from feature space to image space\n",
    "        self.activation_maxpool = None  # Activation for max_pool layer 1 and 2, needed for switches\n",
    "        self.current_layer = None  # Changes as array is passed on\n",
    "        self.f = None  # Filter whose activation is projected down\n",
    "\n",
    "    def project_down(self, image_path, layer, f=None, use_bias=False):\n",
    "        assert type(layer) == int\n",
    "        self.current_layer = layer\n",
    "        self.f = f  # Visualize activation only for this filter\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        self.array = self.conv_sub_models[self.current_layer].predict(image_path)        ##get output data\n",
    "        self.activation_maxpool = [None] + [self.conv_sub_models[i].predict(image_path) for i in (1, 2)]\n",
    "\n",
    "        if f:\n",
    "            self._set_zero_except_maximum()\n",
    "\n",
    "        if self.current_layer >= 5:\n",
    "            self._project_through_split_convolution()  # Deconv (splitted)\n",
    "            self.array = self.array[:, :, 1:-1, 1:-1]  # Unpadding\n",
    "        if self.current_layer >= 4:\n",
    "            self._project_through_split_convolution()  # Deconv (splitted)\n",
    "            self.array = self.array[:, :, 1:-1, 1:-1]  # Unpadding\n",
    "        if self.current_layer >= 3:\n",
    "            self._project_through_convolution()  # Deconv\n",
    "            self.array = self.array[:, :, 1:-1, 1:-1]  # Unpadding\n",
    "            self._unpool()  # Unpooling\n",
    "        if self.current_layer >= 2:\n",
    "            self._project_through_split_convolution()  # Deconv (splitted)\n",
    "            self.array = self.array[:, :, 2:-2, 2:-2]  # Unpadding\n",
    "            self._unpool()  # Unpooling\n",
    "        if self.current_layer >= 1:\n",
    "            self._project_through_convolution()  # Deconv\n",
    "        return self.array\n",
    "\n",
    "    def _project_through_convolution(self):\n",
    "        cl = self.current_layer\n",
    "        assert cl in (1, 3)\n",
    "\n",
    "        # Current Layer names\n",
    "        conv_cl = 'conv_{}'.format(cl)            ##combining strings\n",
    "        deconv_cl = 'deconv_{}'.format(cl)\n",
    "\n",
    "        # Subtract bias\n",
    "        if self.use_bias:\n",
    "            assert self.array.shape == self.bias3D[conv_cl].shape\n",
    "            self.array -= self.bias3D[conv_cl]\n",
    "\n",
    "        # Apply transposed filters\n",
    "        self.array = self.deconv_layers[deconv_cl].predict(self.array)\n",
    "        self.current_layer -= 1\n",
    "\n",
    "    def _project_through_split_convolution(self):\n",
    "        \"\"\"\n",
    "        Split, perform deconvolution on splits, merge\n",
    "        \"\"\"\n",
    "\n",
    "        cl = self.current_layer\n",
    "        assert cl in (2, 4, 5)\n",
    "\n",
    "        # Make sure dimensions are fine\n",
    "        assert self.array.shape[1] == self.channels[cl], 'Channel number incorrect'\n",
    "\n",
    "        # Current Layer names\n",
    "        conv_cl_1 = 'conv_{}_1'.format(cl)\n",
    "        conv_cl_2 = 'conv_{}_2'.format(cl)\n",
    "        deconv_cl_1 = 'deconv_{}_1'.format(cl)\n",
    "        deconv_cl_2 = 'deconv_{}_2'.format(cl)\n",
    "\n",
    "        # Split\n",
    "        activation_cl_1 = self.array[:, : self.channels[cl] // 2]\n",
    "        activation_cl_2 = self.array[:, self.channels[cl] // 2:]\n",
    "\n",
    "        if self.use_bias:\n",
    "            # Subtract biases\n",
    "            assert activation_cl_1.shape == self.bias3D[conv_cl_1].shape\n",
    "            assert activation_cl_2.shape == self.bias3D[conv_cl_2].shape\n",
    "            activation_cl_1 -= self.bias3D[conv_cl_1]\n",
    "            activation_cl_2 -= self.bias3D[conv_cl_2]\n",
    "\n",
    "        # Apply transposed filters\n",
    "        projected_activation_cl_1 = self.deconv_layers[deconv_cl_1].predict(activation_cl_1)\n",
    "        projected_activation_cl_2 = self.deconv_layers[deconv_cl_2].predict(activation_cl_2)\n",
    "\n",
    "        # Merge\n",
    "        self.array = np.concatenate((projected_activation_cl_1, projected_activation_cl_2), axis=1)\n",
    "        assert self.array.shape[1] == self.channels[cl - 1], 'Channel number incorrect'\n",
    "\n",
    "        self.current_layer -= 1\n",
    "\n",
    "    def _unpool(self):\n",
    "        cl = self.current_layer\n",
    "        assert cl in (1, 2), 'Maxpooling only for layer one and two'          ## the 5th doesn't need pooling operate for the deconvolution stops at the last convolution layer\n",
    "        activations = self.activation_maxpool[cl]\n",
    "\n",
    "        # Network parameters for maxpool layers\n",
    "        kernel = 3\n",
    "        stride = 2\n",
    "\n",
    "        # TODO: Simplify to last 2 lines\n",
    "        # Change last to lines to assignment once everything works nicely\n",
    "        assert cl in (1, 2)\n",
    "        if cl == 1:\n",
    "            input_shape = (96, 55, 55)\n",
    "            output_shape = (96, 27, 27)\n",
    "        if cl == 2:\n",
    "            input_shape = (256, 27, 27)\n",
    "            output_shape = (256, 13, 13)\n",
    "        assert activations.shape[1:] == input_shape, \"activations: {} != input_shape: {}\".format(activations.shape[1:],\n",
    "                                                                                                 input_shape)\n",
    "        assert self.array.shape[1:] == output_shape, \"array:{} != output_shape: {}\".format(self.array.shape[1:],\n",
    "                                                                                           output_shape)\n",
    "\n",
    "        reconstructed_activations = np.zeros_like(activations)\n",
    "        for f in range(output_shape[0]):\n",
    "            for i_out in range(output_shape[1]):\n",
    "                for j_out in range(output_shape[2]):\n",
    "                    i_in, j_in = i_out * stride, j_out * stride\n",
    "                    sub_square = activations[0, f, i_in:i_in + kernel, j_in:j_in + kernel]\n",
    "                    max_pos_i, max_pos_j = np.unravel_index(np.nanargmax(sub_square), (kernel, kernel))\n",
    "                    array_pixel = self.array[0, f, i_out, j_out]\n",
    "\n",
    "                    # Since poolings are overlapping, two activations might be reconstructed to same spot\n",
    "                    # Keep the higher activation\n",
    "                    if reconstructed_activations[0, f, i_in + max_pos_i, j_in + max_pos_j] < array_pixel:\n",
    "                        reconstructed_activations[0, f, i_in + max_pos_i, j_in + max_pos_j] = array_pixel\n",
    "        self.array = reconstructed_activations\n",
    "\n",
    "    def _set_zero_except_maximum(self):                        # ?????????\n",
    "        # Set other layers to zero\n",
    "        new_array = np.zeros_like(self.array)\n",
    "        new_array[0, self.f - 1] = self.array[0, self.f - 1]\n",
    "\n",
    "        # Set other activations in same layer to zero\n",
    "        max_index_flat = np.nanargmax(new_array)\n",
    "        max_index = np.unravel_index(max_index_flat, new_array.shape)\n",
    "        self.array = np.zeros_like(new_array)\n",
    "        self.array[max_index] = new_array[max_index]\n",
    "\n",
    "\n",
    "class DeconvOutput:\n",
    "    def __init__(self, unarranged_array, contrast=None):  # Takes output of DeconvNet\n",
    "        self.contrast = contrast\n",
    "        self.array = self._rearrange_array(unarranged_array)\n",
    "        self.image = None\n",
    "\n",
    "    def _rearrange_array(self, unarranged_array):\n",
    "        assert len(unarranged_array.shape) in (3, 4)\n",
    "\n",
    "        # If Array is not yet rearranged\n",
    "        if len(unarranged_array.shape) == 4:\n",
    "            assert unarranged_array.shape[0] == 1\n",
    "            unarranged_array = unarranged_array[0, :, :, :]  # Eliminate batch size dimension\n",
    "            unarranged_array = np.moveaxis(unarranged_array, 0, -1)  # Put channels last\n",
    "\n",
    "            # Contrast\n",
    "            if self.contrast is not None:\n",
    "                percentile = 99\n",
    "                # max_val = np.nanargmax(unarranged_array)\n",
    "                max_val = np.percentile(unarranged_array, percentile)\n",
    "                unarranged_array *= (self.contrast / max_val)\n",
    "\n",
    "            # Undo sample mean subtraction\n",
    "            unarranged_array[:, :, 0] += 123.68\n",
    "            unarranged_array[:, :, 1] += 116.779\n",
    "            unarranged_array[:, :, 2] += 103.939\n",
    "\n",
    "        return unarranged_array\n",
    "\n",
    "    def save_as(self, folder=None, filename='test.JPEG'):\n",
    "        self.image = Image.fromarray(self.array.astype(np.uint8), 'RGB')\n",
    "        if self.image.mode != 'RGB':\n",
    "            self.image = self.image.convert('RGB')\n",
    "\n",
    "        if folder is not None:\n",
    "            assert type(folder) is str\n",
    "            filename = folder + '/' + filename\n",
    "\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "        self.image.save(filename)\n",
    "\n",
    "\n",
    "def visualize_all_filters_in_layer1():\n",
    "    conv_model = AlexNet().model\n",
    "    w = conv_model.get_layer('conv_1').get_weights()[0]\n",
    "    for f in range(96):\n",
    "        wf = w[:, :, :, f]\n",
    "        # scale = min(abs(100/wf.max()),abs(100/wf.min()))\n",
    "        scale = 500\n",
    "        wf *= scale\n",
    "        wf[:, :, 0] += 123.68\n",
    "        wf[:, :, 1] += 116.779\n",
    "        wf[:, :, 2] += 103.939\n",
    "        result = DeconvOutput(wf)\n",
    "        result.save_as(filename='Filters_Layer1_Visualized/filter{}.JPEG'.format(f + 1))\n",
    "\n",
    "\n",
    "def project_complete_image(layer, file_name='Example_JPG/Elephant.jpg'):\n",
    "    conv_base_model = AlexNet().model\n",
    "\n",
    "    projection = Deconvolution(conv_base_model).project_down(file_name, layer=layer, use_bias=True)\n",
    "    original_image = preprocess_image_batch(file_name)\n",
    "\n",
    "    activation_filename = 'test.JPEG'\n",
    "    DeconvOutput(projection).save_as(filename=activation_filename)\n",
    "\n",
    "    original_filename = 'test_original.JPEG'\n",
    "    DeconvOutput(original_image).save_as(filename=original_filename)\n",
    "\n",
    "\n",
    "def visualize_top_images(layer, f, constrast):\n",
    "    \"\"\"\n",
    "    Visualize the activating pixels of the 9 images that maximally activate a given filter in a layer\n",
    "    \"\"\"\n",
    "    conv_base_model = AlexNet().model\n",
    "    get_from_folder = 'Layer{}_Strongest_max_IMG'.format(layer)\n",
    "    save_to_folder = 'Layer{}_Projections_and_Images'.format(layer)\n",
    "    if not os.path.exists(save_to_folder):\n",
    "        os.makedirs(save_to_folder)\n",
    "\n",
    "    for t in range(1, 10):\n",
    "        file_name = '/Layer{}_Filter{}_Top{}.JPEG'.format(layer, f, t)\n",
    "\n",
    "        projection = Deconvolution(conv_base_model).project_down(get_from_folder + file_name, layer, f)\n",
    "        original_image = preprocess_image_batch(get_from_folder + file_name)\n",
    "\n",
    "        activation_filename = save_to_folder + '/Layer{}_Filter{}_Top{}_Activations.JPEG'.format(layer, f, t)\n",
    "        if os.path.exists(activation_filename):\n",
    "            os.remove(activation_filename)\n",
    "        DeconvOutput(projection, constrast).save_as(filename=activation_filename)\n",
    "\n",
    "        original_filename = save_to_folder + '/Layer{}_Filter{}_Top{}.JPEG'.format(layer, f, t)\n",
    "        if os.path.exists(original_filename):\n",
    "            os.remove(original_filename)\n",
    "        DeconvOutput(original_image).save_as(filename=original_filename)\n",
    "\n",
    "\n",
    "def get_bounding_box_coordinates(projection):\n",
    "    combined_channels = np.sum(projection[0], 0)\n",
    "    assert combined_channels.shape[0] == 227\n",
    "    assert combined_channels.shape[1] == 227\n",
    "    arg_positions = np.argwhere(combined_channels)\n",
    "    (xstart, ystart), (xstop, ystop) = arg_positions.min(0), arg_positions.max(0)\n",
    "\n",
    "    # x_diff = xstop-xstart\n",
    "    # y_diff = ystop-ystart\n",
    "    # diff = (x_diff + y_diff)//2\n",
    "    # xstart = (xstart+xstop)//2-diff\n",
    "    # xstop = (xstart+xstop)//2-diff\n",
    "\n",
    "    return (xstart, xstop, ystart, ystop)\n",
    "\n",
    "\n",
    "def draw_bounding_box(input_image, bounding_boxes, c=-100):\n",
    "    assert input_image.shape == (1, 3, 227, 227)\n",
    "    image = np.zeros((1, 3, 235, 235))\n",
    "    image[0, :, 4:-4, 4:-4] = input_image[:, :]\n",
    "\n",
    "    for xstart, xstop, ystart, ystop in bounding_boxes:\n",
    "        xstart += 4\n",
    "        xstop += 4\n",
    "        ystart += 4\n",
    "        ystop += 4\n",
    "\n",
    "        if xstart == 4: xstart = 0\n",
    "        if ystart == 4: ystart = 0\n",
    "        if xstop == 230: xstop = 233\n",
    "        if ystop == 230: ystop = 234\n",
    "\n",
    "        image[0, :, xstart, ystart:ystop + 1] = c\n",
    "        image[0, :, xstart + 1, ystart + 1:ystop] = -c\n",
    "        image[0, :, xstart + 2, ystart + 2:ystop - 1] = c\n",
    "\n",
    "        image[0, :, xstop, ystart:ystop+1] = c\n",
    "        image[0, :, xstop - 1, ystart + 1:ystop] = -c\n",
    "        image[0, :, xstop - 2, ystart + 2:ystop -1] = c\n",
    "\n",
    "        image[0, :, xstart:xstop+1, ystart] = c\n",
    "        image[0, :, xstart + 1:xstop, ystart + 1] = -c\n",
    "        image[0, :, xstart + 2:xstop - 1, ystart + 2] = c\n",
    "\n",
    "        image[0, :, xstart:xstop+1, ystop] = c\n",
    "        image[0, :, xstart + 1:xstop, ystop - 1] = -c\n",
    "        image[0, :, xstart + 2:xstop-1, ystop - 2] = c\n",
    "\n",
    "    return image[:, :, 4:-4, 4:-4]\n",
    "\n",
    "\n",
    "def project_top_layer_filters(img_id=None, deconv_base_model=None):\n",
    "    if img_id is None:                                     ## the operate when input variables is none\n",
    "        img_id = randint(1, 50000)\n",
    "    if deconv_base_model is None:\n",
    "        deconv_base_model = Deconvolution(AlexNet().model)\n",
    "\n",
    "    path = get_path_from_id(img_id)\n",
    "    save_to_folder = 'TopFilters'\n",
    "\n",
    "    projections = []\n",
    "    box_borders = []\n",
    "    layer = 5\n",
    "    for max_filter in get_strongest_filters(img_id, layer, top=2):\n",
    "        projection = deconv_base_model.project_down(path, layer, max_filter)\n",
    "\n",
    "        # Increase Contrast\n",
    "        percentile = 99\n",
    "        max_val = np.percentile(projection, percentile)\n",
    "        projection *= (20 / max_val)\n",
    "        box_borders.append(get_bounding_box_coordinates(projection))\n",
    "        projections.append(projection)\n",
    "\n",
    "    superposed_projections = np.maximum.reduce(projections)\n",
    "    # superposed_projections = sum(projections)\n",
    "    assert superposed_projections.shape == projections[0].shape\n",
    "\n",
    "    DeconvOutput(superposed_projections).save_as(save_to_folder, '{}_activations.JPEG'.format(img_id))\n",
    "\n",
    "    original_image = preprocess_image_batch(path)\n",
    "    original_image = draw_bounding_box(original_image, box_borders)\n",
    "    DeconvOutput(original_image).save_as(save_to_folder, '{}.JPEG'.format(img_id))\n",
    "\n",
    "\n",
    "def project_multiple_layer_filters(img_id=None, deconv_base_model=None):\n",
    "    if img_id is None:\n",
    "        img_id = randint(1, 50000)\n",
    "    if deconv_base_model is None:\n",
    "        deconv_base_model = Deconvolution(AlexNet().model)\n",
    "\n",
    "    path = get_path_from_id(img_id)\n",
    "    save_to_folder = 'MultipleLayers'\n",
    "\n",
    "    projections = []\n",
    "    box_borders = []\n",
    "    contrast = [None, 1, 3, 7, 13, 22]\n",
    "    for layer in (1, 2, 3, 4, 5):\n",
    "        assert get_strongest_filter(img_id, layer) == get_strongest_filters(img_id, layer, top=1)\n",
    "        max_filter = get_strongest_filter(img_id, layer)\n",
    "        if layer == 1: print(img_id, ': ', max_filter)\n",
    "        projection = deconv_base_model.project_down(path, layer, max_filter)\n",
    "\n",
    "        if layer != 1:\n",
    "            # Increase Contrast\n",
    "            percentile = 99\n",
    "            # max_val = np.nanargmax(unarranged_array)\n",
    "            max_val = np.percentile(projection, percentile)\n",
    "            projection *= (contrast[layer] / max_val)\n",
    "        else:\n",
    "            projection *= 0.3\n",
    "\n",
    "        box_borders.append(get_bounding_box_coordinates(projection))\n",
    "\n",
    "        # x_diff[layer].append(box_borders[-1][1] - box_borders[-1][0])\n",
    "        # y_diff[layer].append(box_borders[-1][3] - box_borders[-1][2])\n",
    "\n",
    "        projections.append(projection)\n",
    "    superposed_projections = np.maximum.reduce(projections)\n",
    "    # superposed_projections = sum(projections)\n",
    "    assert superposed_projections.shape == projections[0].shape\n",
    "    DeconvOutput(superposed_projections).save_as(save_to_folder, '{}_activations.JPEG'.format(img_id))\n",
    "\n",
    "    original_image = preprocess_image_batch(path)\n",
    "    original_image = draw_bounding_box(original_image, box_borders)\n",
    "    DeconvOutput(original_image).save_as(save_to_folder, '{}.JPEG'.format(img_id))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    deconv_base_model = Deconvolution(AlexNet().model)\n",
    "    # for _ in range(15):\n",
    "    #     #project_top_layer_filters(deconv_base_model=deconv_base_model)\n",
    "    #     #project_multiple_layer_filters(deconv_base_model=deconv_base_model)\n",
    "    # project_multiple_layer_filters(deconv_base_model=deconv_base_model)\n",
    "    #for img_id in (50011,50012,50013,50014,50015):\n",
    "        #project_multiple_layer_filters(img_id=img_id, deconv_base_model=deconv_base_model)\n",
    "    for img_id in (50016,50017,50018):\n",
    "        project_top_layer_filters(img_id=img_id, deconv_base_model=deconv_base_model)\n",
    "\n",
    "    pass\n",
    "    # visualize_top_images(layer=5, f=4, constrast=13)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
